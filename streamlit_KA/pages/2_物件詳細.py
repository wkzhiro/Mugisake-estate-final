import streamlit as st
import numpy as np

# # Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—ã—æ ¼ç´
# import pandas as pd
# import gspread
# from oauth2client.service_account import ServiceAccountCredentials
# from gspread_dataframe import get_as_dataframe

# scope =['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
# creds = ServiceAccountCredentials.from_json_keyfile_name('grspread_key_mugisake.json', scope)
# client = gspread.authorize(creds)

# sheet = client.open("Mugisake_KA01").worksheet('sheet5')
# df = get_as_dataframe(sheet)

#Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—ã—æ ¼ç´(Streamlitãƒ‡ãƒ—ãƒ­ã‚¤ç”¨2)
from google.oauth2 import service_account
from gsheetsdb import connect
import pandas as pd
# Create a connection object.
credentials = service_account.Credentials.from_service_account_info( st.secrets["gcp_service_account"], scopes=[ "https://www.googleapis.com/auth/spreadsheets", ],
)
conn = connect(credentials=credentials)
def run_query(query):
    rows = conn.execute(query, headers=1)
    return rows
sheet_url = st.secrets["private_gsheets_url"]
rows = run_query(f'SELECT * FROM "{sheet_url}"')
# ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›ã—è¡¨ç¤ºã™ã‚‹
row_list = []
for row in rows: row_list.append(row)
df=pd.DataFrame(row_list)

# ãƒ‡ãƒ¼ã‚¿ã®æ´—æµ„
NaN_dell_column = ["name","price","address","layout","age","area","traffic_tx"] #æ¬ æå€¤ã®å‰Šé™¤
df = df.dropna(subset = NaN_dell_column,axis = 0)

# df["price"] = df["price"]/10000 #ä¾¡æ ¼ã‚’ï¼ˆä¸‡å††ï¼‰ã«å¤‰æ›´
df['station'] = df['traffic_tx'].str.split(pat='ã€Œ',expand=True)[1].str.split(pat='ã€',expand=True)[0] #é§…åå–å¾—
df['name'] = df['name'].str.replace('ã€ãƒãƒ³ã‚·ãƒ§ãƒ³ã€‘','')
df['layout'] = df['layout'].str.replace('ï¼ˆç´æˆ¸ï¼‰','')

int_convert_column = ["price",'price_kanri','price_tsumitate',"area","age","floor","time_walk"] #æ•´æ•°å‹ã«å¤‰æ›
df[int_convert_column] = df[int_convert_column].astype('int')

#------------------------page-Detail------------------------

st.title('ç‰©ä»¶è©³ç´°')
st.write("æ°—ã«ãªã‚‹ç‰©ä»¶ã®è©³ç´°ã«åŠ ãˆã¦ã€ã€ŒãŠå¾—åº¦ã€ã€Œå‘¨è¾ºåœ°å›³ã€ã€Œãƒã‚¶ãƒ¼ãƒ‰æƒ…å ±ã€ã‚’ãŠçŸ¥ã‚‰ã›ï¼")

id_home = int(st.text_input('è©³ç´°ã‚’è¡¨ç¤ºã—ãŸã„ç‰©ä»¶ç•ªå·ã¯ï¼Ÿ', "0"))


# è¡¨ã®è¡¨ç¤º
df_detail = df.loc[id_home]

st.write('### ğŸŒŸãŠå¾—åº¦ğŸŒŸ')
df_detail1 = df_detail[['predicted_price','discounted_price']]
df_detail1 = df_detail1.set_axis(["AIãŒäºˆæƒ³ã—ãŸä¾¡æ ¼(å††)","ãŠå¾—åº¦(å††)"]) #åˆ—åã®å¤‰æ›´
st.dataframe(df_detail1, width=2000,height=110)

st.write('### è©³ç´°ãƒ‡ãƒ¼ã‚¿')
df_detail1 = df_detail[['name','price','price_kanri','price_tsumitate',
    'layout','area','age','direction','floor',
    'traffic_tx','url']]
df_detail1 = df_detail1.set_axis(["ãƒãƒ³ã‚·ãƒ§ãƒ³å","ä¾¡æ ¼(å††)","ç®¡ç†è²»(å††/æœˆ)","ä¿®ç¹•ç©ç«‹é‡‘(å††/æœˆ)",
    "é–“å–ã‚Š","é¢ç©(m2)","ç¯‰å¹´","æ–¹è§’","éšæ•°",
    "æœ€å¯„é§…","Link"]) #åˆ—åã®å¤‰æ›´
st.dataframe(df_detail1, width=2000,height=420)


# åœ°å›³ã®è¡¨ç¤º
import folium
from streamlit_folium import folium_static
# ç·¯åº¦çµŒåº¦ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã™ã‚‹
df_map = pd.DataFrame(
    data=[[df_detail['Ido'],df_detail['Keido']]],
    index=[df_detail['name']],
    columns=["x","y"]
)
# ãƒ‡ãƒ¼ã‚¿ã‚’åœ°å›³ã«æ¸¡ã™é–¢æ•°ã‚’ä½œæˆã™ã‚‹
def AreaMarker(df,m):
    for index, r in df.iterrows(): 

        # ãƒ”ãƒ³ã‚’ãŠã
        folium.Marker(
            location=[r.x, r.y],
            popup=index,
        ).add_to(m)

        # å††ã‚’é‡ã­ã‚‹
        folium.Circle(
            radius=rad*1000,
            location=[r.x, r.y],
            popup=index,
            color="yellow",
            fill=True,
            fill_opacity=0.07
        ).add_to(m)
# ç”»é¢ä½œæˆ
st.write('### å‘¨è¾ºåœ°å›³')
rad = st.slider('æ‹ ç‚¹ã‚’ä¸­å¿ƒã¨ã—ãŸå††ã®åŠå¾„ï¼ˆkmï¼‰',
                value=1,min_value=0, max_value=5) # ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’ã¤ã‘ã‚‹
# st.subheader("å„æ‹ ç‚¹ã‹ã‚‰ã®è·é›¢{:,}km".format(rad)) # åŠå¾„ã®è·é›¢ã‚’è¡¨ç¤º
m = folium.Map(df_map, zoom_start=15) # åœ°å›³ã®åˆæœŸè¨­å®š
AreaMarker(df_map,m) # ãƒ‡ãƒ¼ã‚¿ã‚’åœ°å›³æ¸¡ã™
folium_static(m) # åœ°å›³æƒ…å ±ã‚’è¡¨ç¤º



#ãƒã‚¶ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã®è¡¨ç¤º
import os, json, requests, math, sys
from skimage import io
from io import BytesIO
import cv2



def get_tile_num(lat, lon, zoom):
    """
    ç·¯åº¦çµŒåº¦ã‹ã‚‰ã‚¿ã‚¤ãƒ«åº§æ¨™ã‚’å–å¾—ã™ã‚‹
    Parameters
    ----------
    lat : number 
        ã‚¿ã‚¤ãƒ«åº§æ¨™ã‚’å–å¾—ã—ãŸã„åœ°ç‚¹ã®ç·¯åº¦(deg) 
    lon : number 
        ã‚¿ã‚¤ãƒ«åº§æ¨™ã‚’å–å¾—ã—ãŸã„åœ°ç‚¹ã®çµŒåº¦(deg) 
    zoom : int 
        ã‚¿ã‚¤ãƒ«ã®ã‚ºãƒ¼ãƒ ç‡
    Returns
    -------
    xtile : int
        ã‚¿ã‚¤ãƒ«ã®Xåº§æ¨™
    ytile : int
        ã‚¿ã‚¤ãƒ«ã®Yåº§æ¨™
    """
    # https://wiki.openstreetmap.org/wiki/Slippy_map_tilenames#Python
    lat_rad = math.radians(lat)
    n = 2.0 ** zoom
    xtile = int((lon + 180.0) / 360.0 * n)
    ytile = int((1.0 - math.log(math.tan(lat_rad) + (1 / math.cos(lat_rad))) / math.pi) / 2.0 * n)
    return (xtile, ytile)

def get_tile_bbox(xtile, ytile, z):


    """
    ã‚¿ã‚¤ãƒ«åº§æ¨™ã‹ã‚‰ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’å–å¾—ã™ã‚‹
    https://tools.ietf.org/html/rfc7946#section-5
    Parameters
    ----------
    z : int 
        ã‚¿ã‚¤ãƒ«ã®ã‚ºãƒ¼ãƒ ç‡ 
    x : int 
        ã‚¿ã‚¤ãƒ«ã®Xåº§æ¨™ 
    y : int 
        ã‚¿ã‚¤ãƒ«ã®Yåº§æ¨™ 
    Returns
    -------
    bbox: tuple of number
        ã‚¿ã‚¤ãƒ«ã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹
        (å·¦ä¸‹çµŒåº¦, å·¦ä¸‹ç·¯åº¦, å³ä¸ŠçµŒåº¦, å³ä¸Šç·¯åº¦)
    """
    def num2deg(xtile, ytile, z):
        # https://wiki.openstreetmap.org/wiki/Slippy_map_tilenames#Python
        n = 2.0 ** z
        lon_deg = xtile / n * 360.0 - 180.0
        lat_rad = math.atan(math.sinh(math.pi * (1 - 2 * ytile / n)))
        lat_deg = math.degrees(lat_rad)
        return (lon_deg, lat_deg)
    
    right_top = num2deg(xtile + 1, ytile, z)
    left_bottom = num2deg(xtile, ytile + 1, z)
    return (left_bottom[0], left_bottom[1], right_top[0], right_top[1])

def get_tile_lonlats(zoom, xtile, ytile):
    """
    ã‚¿ã‚¤ãƒ«ã®å„ãƒ”ã‚¯ã‚»ãƒ«ã®å·¦ä¸Šéš…ã®çµŒåº¦ç·¯åº¦ã‚’å–å¾—ã™ã‚‹
    Parameters
    ----------
    z : int 
        ã‚¿ã‚¤ãƒ«ã®ã‚ºãƒ¼ãƒ ç‡ 
    x : int 
        ã‚¿ã‚¤ãƒ«ã®Xåº§æ¨™ 
    y : int 
        ã‚¿ã‚¤ãƒ«ã®Yåº§æ¨™ 
    Returns
    -------
    lonlats: ndarray
        ã‚¿ã‚¤ãƒ«ã®å„ãƒ”ã‚¯ã‚»ãƒ«ã®çµŒåº¦ç·¯åº¦
        256*256*2ã®numpyé…åˆ—
        çµŒåº¦ã€ç·¯åº¦ã®é †
    """
    x = int(xtile * 2**8)
    y = int(ytile * 2**8)
    z = zoom + 8

    lonlats = np.zeros((256,256,2))
    for i in range(256):
        for j in range(256):
            bbox = get_tile_bbox(z, x + j, y + i)
            lonlats[i,j,:] = [bbox[0], bbox[3]]
    return lonlats

def get_flood_image(z, x, y, params={}):
    """
    æµ¸æ°´åŸŸã®ã‚¿ã‚¤ãƒ«ç”»åƒã‚’å–å¾—ã™ã‚‹
    Parameters
    ----------
    z : int
        ã‚¿ã‚¤ãƒ«ã®ã‚ºãƒ¼ãƒ ç‡
    x : int
        ã‚¿ã‚¤ãƒ«ã®Xåº§æ¨™
    y : int
        ã‚¿ã‚¤ãƒ«ã®Yåº§æ¨™
    option : dict
        APIãƒ‘ã‚¹ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³(entityId)
    params : dict
        ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    Returns
    -------
    img: ndarray
        ã‚¿ã‚¤ãƒ«ç”»åƒ
        https://disaportal.gsi.go.jp/hazardmap/copyright/opendata.html#l2shinsuishin_kuni
    """
    url = 'https://disaportaldata.gsi.go.jp/raster/01_flood_l2_shinsuishin_data/{}/{}/{}.png'.format(z, x, y)
    r = requests.get(url, params=params)
    if not r.status_code == requests.codes.ok:
        r.raise_for_status()
    return io.imread(BytesIO(r.content))

def get_map_image(z, x, y, params={}):
    """
    æµ¸æ°´åŸŸã®ã‚¿ã‚¤ãƒ«ç”»åƒã‚’å–å¾—ã™ã‚‹
    Parameters
    ----------
    z : int
        ã‚¿ã‚¤ãƒ«ã®ã‚ºãƒ¼ãƒ ç‡
    x : int
        ã‚¿ã‚¤ãƒ«ã®Xåº§æ¨™
    y : int
        ã‚¿ã‚¤ãƒ«ã®Yåº§æ¨™
    option : dict
        APIãƒ‘ã‚¹ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³(entityId)
    params : dict
        ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    Returns
    -------
    img: ndarray
        ã‚¿ã‚¤ãƒ«ç”»åƒ
        https://disaportal.gsi.go.jp/hazardmap/copyright/opendata.html#l2shinsuishin_kuni
    """
    url = 'https://cyberjapandata.gsi.go.jp/xyz/seamlessphoto/{}/{}/{}.jpg'.format(z, x, y)
    r = requests.get(url, params=params)
    if not r.status_code == requests.codes.ok:
        r.raise_for_status()
    return io.imread(BytesIO(r.content))

def get_combined_image(get_image_func, z, topleft_x, topleft_y, size_x=1, size_y=1, params={}):
    """
    çµåˆã•ã‚ŒãŸã‚¿ã‚¤ãƒ«ç”»åƒã‚’å–å¾—ã™ã‚‹
    Parameters
    ----------
    get_image_func : function
        ã‚¿ã‚¤ãƒ«ç”»åƒå–å¾—ãƒ¡ã‚½ãƒƒãƒ‰
        å¼•æ•°ã¯z, x, y, option, params
    z : int
        ã‚¿ã‚¤ãƒ«ã®ã‚ºãƒ¼ãƒ ç‡
    topleft_x : int
        å·¦ä¸Šã®ã‚¿ã‚¤ãƒ«ã®Xåº§æ¨™
    topleft_y : int
        å·¦ä¸Šã®ã‚¿ã‚¤ãƒ«ã®Yåº§æ¨™
    size_x : int
         ã‚¿ã‚¤ãƒ«ã‚’çµŒåº¦æ–¹å‘ã«ã¤ãªãã‚ã›ã‚‹æšæ•°
    size_y : int
        ã‚¿ã‚¤ãƒ«ã‚’ç·¯åº¦æ–¹å‘ã«ã¤ãªãã‚ã›ã‚‹æšæ•°
    option : dict
        APIãƒ‘ã‚¹ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³(z,x,yé™¤ã)
    params : dict
        ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    Returns
    -------
    combined_image: ndarray
        çµåˆã•ã‚ŒãŸã‚¿ã‚¤ãƒ«ç”»åƒ
    """
    rows = []
    blank = np.zeros((256, 256, 4), dtype=np.uint8)
    for y in range(size_y):
        row = []
        for x in range(size_x):
            try:
                img = get_image_func(z, topleft_x + x-math.floor(size_x/2), topleft_y + y-math.floor(size_y/2), params)
            except Exception as e:
                img = blank
            row.append(img)
        rows.append(np.hstack(row))
    return  np.vstack(rows)

def make_hazard_map(z, y_lat, x_lon, size_x=1.0, size_y=1.0,x_offset=0 ,y_offset=0 , params={}):
    x,y = get_tile_num(y_lat, x_lon, z)
    
    # æµ¸æ°´åŸŸã‚’å–å¾—ã—ã¦æç”»
    combined_flood = get_combined_image(get_flood_image, z, x, y,size_x,size_y)
    combined_flood = combined_flood[:,:,0:3]
    combined_flood  = np.where(combined_flood==[0,0,0],[255,255,255],combined_flood)
    combined_flood = np.array(combined_flood, dtype=np.uint8)

    # å†™çœŸã‚’å–å¾—ã—ã¦æç”»
    combined_base = get_combined_image(get_map_image, z, x, y,size_x,size_y)
    
    #ã€€ç”»åƒã‚’åˆæˆ
    blended = cv2.addWeighted(src1=combined_base,alpha=0.5,src2=combined_flood,beta=0.5,gamma=0)
    
    bbox_nw = get_tile_bbox(x-math.floor(size_x/2),y-math.floor(size_y/2),z) #çµåˆã•ã‚ŒãŸç”»åƒã®å·¦ä¸Šã®ã‚¿ã‚¤ãƒ«åº§æ¨™ã®ç·¯åº¦çµŒåº¦
    bbox_se = get_tile_bbox(x-math.floor(size_x/2)+size_x-1,y-math.floor(size_y/2)+size_y-1,z) #çµåˆã•ã‚ŒãŸç”»åƒã®å³ä¸‹ã®ã‚¿ã‚¤ãƒ«åº§æ¨™ã®ç·¯åº¦çµŒåº¦
    min_lon = bbox_nw[0]
    min_lat = bbox_se[1] 
    
    longitudes = []
    latitudes = []
    longitudes.append(x_lon - min_lon)
    latitudes.append(y_lat - min_lat)
    
    diff_long_range = bbox_se[2] - bbox_nw[0] # çµŒåº¦ã®ç¯„å›²ä¸Šé™
    diff_lat_range = bbox_nw[3] - bbox_se[1] # ç·¯åº¦ã®ç¯„å›²ä¸Šé™
    x_img_size = blended.shape[0] #ç”»åƒã®ã‚µã‚¤ã‚ºã‚’æ±‚ã‚ã‚‹ï¼ˆxè»¸æ–¹å‘ï¼‰
    y_img_size = blended.shape[1] #ç”»åƒã®ã‚µã‚¤ã‚ºã‚’æ±‚ã‚ã‚‹ï¼ˆyè»¸æ–¹å‘ï¼‰

    onepix_degree_long = diff_long_range/x_img_size
    onepix_degree_lat = diff_lat_range/y_img_size
    
    pixel_x = longitudes[0]/onepix_degree_long
    pixel_y = latitudes[0]/onepix_degree_lat
    pixel_x = np.array(pixel_x,dtype = 'int16')
    pixel_y = np.array(pixel_y,dtype = 'int16')
    
    from urllib.request import urlopen
    def urlread(url, flags=cv2.IMREAD_UNCHANGED):
        response = urlopen(url)
        img = np.asarray(bytearray(response.read()), dtype=np.uint8)
        img = cv2.imdecode(img, flags)
        return img

    legend_img = urlread('https://disaportal.gsi.go.jp/hazardmap/copyright/img/shinsui_legend2-1.png')    
    # legend_img = cv2.imread('shinsui_legend2-1.png')
    legend_img = cv2.cvtColor(legend_img, cv2.COLOR_BGR2RGB)
    
    blended_mix = blended 
    blended_mix[y_offset:y_offset+legend_img.shape[0], x_offset:x_offset+legend_img.shape[1]] = legend_img
    cv2.circle(blended_mix, center=(int(pixel_x), y_img_size - int(pixel_y)), radius=15, color = (255, 0, 0), thickness=-1, lineType=cv2.LINE_AA,shift=0)

    return blended_mix

def cal_flood_risk(z, y_lat, x_lon, size_x=1.0, size_y=1.0,x_offset=0 ,y_offset=0 , params={}):
    x,y = get_tile_num(y_lat, x_lon, z)
    
    # æµ¸æ°´åŸŸã‚’å–å¾—ã—ã¦æç”»
    combined_flood = get_combined_image(get_flood_image, z, x, y,size_x,size_y)
    combined_flood = combined_flood[:,:,0:3]
    
    bbox_nw = get_tile_bbox(x-math.floor(size_x/2),y-math.floor(size_y/2),z) #çµåˆã•ã‚ŒãŸç”»åƒã®å·¦ä¸Šã®ã‚¿ã‚¤ãƒ«åº§æ¨™ã®ç·¯åº¦çµŒåº¦
    bbox_se = get_tile_bbox(x-math.floor(size_x/2)+size_x-1,y-math.floor(size_y/2)+size_y-1,z) #çµåˆã•ã‚ŒãŸç”»åƒã®å³ä¸‹ã®ã‚¿ã‚¤ãƒ«åº§æ¨™ã®ç·¯åº¦çµŒåº¦
    min_lon = bbox_nw[0]
    min_lat = bbox_se[1] 

    longitudes = []
    latitudes = []
    longitudes.append(x_lon - min_lon)
    latitudes.append(y_lat - min_lat)
    
    diff_long_range = bbox_se[2] - bbox_nw[0] # çµŒåº¦ã®ç¯„å›²ä¸Šé™
    diff_lat_range = bbox_nw[3] - bbox_se[1] # ç·¯åº¦ã®ç¯„å›²ä¸Šé™
    x_img_size = combined_flood.shape[0] #ç”»åƒã®ã‚µã‚¤ã‚ºã‚’æ±‚ã‚ã‚‹ï¼ˆxè»¸æ–¹å‘ï¼‰
    y_img_size = combined_flood.shape[1] #ç”»åƒã®ã‚µã‚¤ã‚ºã‚’æ±‚ã‚ã‚‹ï¼ˆyè»¸æ–¹å‘ï¼‰

    onepix_degree_long = diff_long_range/x_img_size
    onepix_degree_lat = diff_lat_range/y_img_size
    
    pixel_x = longitudes[0]/onepix_degree_long
    pixel_y = latitudes[0]/onepix_degree_lat
    pixel_x = np.array(pixel_x,dtype = 'int16')
    pixel_y = np.array(pixel_y,dtype = 'int16')
    
    from urllib.request import urlopen
    def urlread(url, flags=cv2.IMREAD_UNCHANGED):
        response = urlopen(url)
        img = np.asarray(bytearray(response.read()), dtype=np.uint8)
        img = cv2.imdecode(img, flags)
        return img

    dtli_img = urlread('https://disaportal.gsi.go.jp/hazardmap/copyright/img/shinsui_legend2-1.png')
    # dtli_img = cv2.imread('shinsui_legend2-1.png')
    dtli_img = cv2.cvtColor(dtli_img, cv2.COLOR_BGR2RGB)
    
    risk_level = {}
    risk_level["0"] = "å®‰å…¨"
    risk_level["1"] = "åºŠä¸‹æµ¸æ°´ãƒ»è†ä¸‹ä»¥ä¸‹"
    risk_level["2"] = "ï¼‘éšæµ¸æ°´"
    risk_level["3"] = "ï¼’éšæµ¸æ°´"
    risk_level["4"] = "ãã‚ã‚ã¦å±é™ºï¼ˆ5mä»¥ä¸Šï¼‰"
    
    total = 0
    
    for x in range(100):
        for y in range(100):
            print(pixel_x-50+x,pixel_y-50+y)
            if list(combined_flood[pixel_x-50+x,pixel_y-50+y,:]) == [247,245,169]:
                total += 1
            elif list(combined_flood[pixel_x-50+x,pixel_y-50+y,:]) ==  [255,216,192]:
                total += 2
            elif list(combined_flood[pixel_x-50+x,pixel_y-50+y,:]) ==  [255,183,183]:
                total += 3
            elif list(combined_flood[pixel_x-50+x,pixel_y-50+y,:]) ==  [255,145,145]:
                total += 4
            else:
                total +=0
    
    risk = total/10000
    
    return risk_level[str(int(risk))]

def cal_eq_pb(lat, lon):
    position = str(lon)+','+str(lat)
    url_eq='https://www.j-shis.bosai.go.jp/map/api/fltsearch?position={}&epsg=4612&mode=C&version=Y2022&case=AVR&period=P_T30&format=json&ijma=60'.format(position)
    result_eq = requests.get(url_eq).json()
    
    for i in range(len(result_eq['Fault'])):
        if i == 0:
            probability = 1-float(result_eq['Fault'][i]['probability'])
        else:
            probability *=  (1-float(result_eq['Fault'][i]['probability']))

    total_probability = 1- probability
    
    return total_probability*100

if id_home>=0:
    #ç‰©ä»¶åã‚ã‚‹ã„ã¯æœ€å¯„ã‚Šé§…ã§å–å¾—
    item_lat = df.iloc[int(id_home),18]
    item_lon = df.iloc[int(id_home),17]

    # st.write("æœ€å¯„ã‚Šé§…ã¯é’ä¸¸ã§è¡¨ç¤º")
    risk_flood = cal_flood_risk(z=18, y_lat = item_lat, x_lon=item_lon, size_x=4, size_y=4,x_offset=0 ,y_offset=0 , params={})
    risk_eq = cal_eq_pb(item_lat, item_lon)

    st.write('### ãƒã‚¶ãƒ¼ãƒ‰æƒ…å ±')
    st.write("50å¹´ä»¥å†…ã«6å¼·ä»¥ä¸Šã®åœ°éœ‡ç™ºç”Ÿç¢ºç‡ï¼š",format(risk_eq,'.1f'),"ï¼…")
    st.write("æœ€å¤§ã®æ´ªæ°´è¢«å®³ï¼š", risk_flood)
    st.image(make_hazard_map(z=16,  y_lat= item_lat, x_lon = item_lon, size_x=4, size_y=4,x_offset=0 ,y_offset=0 , params={}))

